{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODIFICADO DE cpv2010arg.py en https://github.com/abenassi/pyredatam/blob/1480c481feb0698d54b59c3c17e52661a8c793df/pyredatam/cpv2010arg.py\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import import_ipynb\n",
    "from Redapy_query import query_final ## el código esta en el notebook llamado Redapy_query\n",
    "import redapy\n",
    "import datetime\n",
    "begin_time = datetime.datetime.now()\n",
    "\n",
    "# area = [\"Distrito\"]\n",
    "# var1 = [\"Poblacio.PAREA\"]\n",
    "# var2 = [\"Poblacio.C5P82\"]\n",
    "# selection = [\"Provinci 1501\"]\n",
    "# filter_a = \"Distrito\"\n",
    "\n",
    "# query = query_final(tipo=\"frequency\",variables1=var1,area_break=area)\n",
    "#query = query_final(tipo=\"frequency\",variables1=var1,area_break=area)\n",
    "\n",
    "ser = Service(r'C:\\\\Users\\\\Dieguinchi\\\\Desktop\\\\chromedriver.exe')\n",
    "# BASE_URL = \"https://censos2017.inei.gob.pe/bininei/RpWebStats.exe/CmdSet?BASE=CPV2017DI&ITEM=PROGRED&lang=esp\"\n",
    "\n",
    "def make_query(query, url): # hace consulta \"query\" a redatam a través de procesador estadístico online\n",
    "    print('Scrapeo iniciado')\n",
    "    options = webdriver.ChromeOptions()#carga configuración del webdriver\n",
    "    options.headless = True\n",
    "    driver = webdriver.Chrome(options=options, service=ser)# el driver debe estar en archivos del pc. puede descargarse de https://chromedriver.chromium.org/downloads\n",
    "    try: driver.get(url) # abre pagina web de redatam\n",
    "    except: print('No se pudo abrir páginade REDATAM')\n",
    "    print('Se cargó página REDATAM con éxito')\n",
    "    query_input = driver.find_element(By.TAG_NAME,\"textarea\")# ubica linea de comandos\n",
    "#     query_input.send_keys(query.decode(\"utf-8\", \"ignore\"))\n",
    "    query_input.send_keys(query) # escribe consulta en línea de comandos\n",
    "    submit = driver.find_element(By.NAME,\"Submit\") #Busca botón \"Ejecutar\"\n",
    "    submit.click()# clickea en \"Ejecutar\" y ejecuta consulta\n",
    "    try: \n",
    "        WebDriverWait(driver, 3).until(lambda driver: len(driver.find_elements(By.XPATH,\"//h2[contains(text(),'500 - Internal server error.')]\")) == 1)\n",
    "        print('No cargó la tabla. Error 505')\n",
    "        return \"\"\n",
    "    except: \n",
    "        print('Iniciando scrapeo...')\n",
    "        WebDriverWait(driver, 999999).until(lambda driver: len(driver.find_elements(By.XPATH,\"//*[contains(text(),'Descargar en formato Excel')]\")) == 1)#espera 999 segundos o a que se muestren todas las tablas solicitadas, es decir, debe mostrar Descargar en formato Excel la misma cantidad de veces que la cantidad de variables de la solicitud \n",
    "        print('La tabla cargó correctamente')\n",
    "        html = driver.find_element(By.ID,\"tab-output\")# obtiene unicamente la tabla de resultados\n",
    "        html = html.get_attribute('outerHTML')# obtiene el html de la tabla de resultados\n",
    "        driver.close() # cierra navegador\n",
    "        return html # devuelve html con tabla de resultados\n",
    "\n",
    "def make_dataframe(html): # crea dataframe con resultados\n",
    "    try: \n",
    "        temp_table = pd.read_html(html) # lee todos los dataframes de la tabla de resultados\n",
    "        print('Tabla scrapeada con éxito en:')\n",
    "        tiempo=datetime.datetime.now() - begin_time\n",
    "        print(tiempo)\n",
    "        return temp_table\n",
    "    except: \n",
    "        print('No se logró scrapear la tabla')\n",
    "     # devuelve lista con dataframes\n",
    "\n",
    "# concatena dataframes de la tabla de resultados en un solo dataframe\n",
    "# merged = pd.concat(make_dataframe(make_query(query)))\n",
    "\n",
    "# Excelwriter = pd.ExcelWriter(\"tablas.xlsx\",engine=\"xlsxwriter\") #exporta en excel dataframe final\n",
    "# merged.to_excel(Excelwriter)\n",
    "# Excelwriter.save()\n",
    "# print(datetime.datetime.now() - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapeo iniciado\n",
      "Se cargó página REDATAM con éxito\n",
      "Iniciando scrapeo...\n",
      "La tabla cargó correctamente\n",
      "Tabla scrapeada con éxito en:\n",
      "0:01:57.081761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dieguinchi\\AppData\\Local\\Temp\\ipykernel_19692\\150765746.py:19: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  Excelwriter.save()\n"
     ]
    }
   ],
   "source": [
    "# area = [\"Departam\"]\n",
    "# var1 = [\"Poblacio.P03ESC\"]\n",
    "# var2 = [\"Poblacio.C5P20CODA\"]\n",
    "# selection = [\"Provinci 1501\"]\n",
    "# filter_a = \"Distrito\"\n",
    "\n",
    "# # query = query_final(tipo=\"frequency\",variables1=var1,area_break=area)\n",
    "# query = query_final(tipo=\"Frequency\",variables1=var1,area_break=area)\n",
    "\n",
    "# BASE_URL = \"https://censos2017.inei.gob.pe/bininei/RpWebStats.exe/CmdSet?BASE=CPV2017DI&ITEM=PROGRED&lang=esp\"\n",
    "\n",
    "# merged = pd.concat(make_dataframe(make_query(query,BASE_URL)))\n",
    "\n",
    "# # df = redapy.tabla_cruzada(merged)\n",
    "# df = redapy.conversion_redatam_matriz(merged)\n",
    "\n",
    "# Excelwriter = pd.ExcelWriter(\"tablas.xlsx\",engine=\"xlsxwriter\") #exporta en excel dataframe final\n",
    "# df.to_excel(Excelwriter)\n",
    "# Excelwriter.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import selenium\n",
    "# print(selenium.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
